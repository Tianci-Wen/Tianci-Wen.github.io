
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110862391-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-110862391-1');
  </script>

  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">

  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <link rel="icon" type="image/png" href="img/seal_icon.png">
  <title>Ben Mildenhall</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>

  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Ben Mildenhall</name>
        </p><p>I am a research scientist at <a href="https://ai.google/research">Google Research</a>, where I work on problems in computer vision and graphics. I recently received my PhD from <a href="http://eecs.berkely.edu">UC Berkeley</a>, where I was advised by <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a> and supported by a <a href="http://hertzfoundation.org/">Hertz fellowship</a>.
        </p>
        <p>
          In the summer of 2017, I was an intern in <a href="http://graphics.stanford.edu/~levoy/">Marc Levoy's</a> group in <a href="https://research.google.com/">Google Research</a>. In the summer of 2018, I worked with <a href="https://github.com/rodrygojose">Rodrigo Ortiz-Cayon</a> and <a href="https://abhishekkar.info/">Abhishek Kar</a> at <a href="https://fyusion.com/">Fyusion</a>.
          I did my undergrad at <a href="http://cs.stanford.edu">Stanford University</a> and worked at <a href="https://graphics.pixar.com/research/">Pixar Research</a> in the summer of 2014.
        </p>
        <p align=center>
          <a href="mailto:bmild@cs.berkeley.edu">Email</a> &nbsp/&nbsp
          <a href="data/cv.pdf">CV</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=NozIDL8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://twitter.com/BenMildenhall">Twitter</a> &nbsp/&nbsp
          <a href="https://github.com/bmild">GitHub</a> 
        </p>
        </td>
        <td width="33%">
	  <a href="img/ben_vive.jpg">
        <img src="img/benface2019.png" width="250px"></a>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
          

          </p>
        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    
          <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="img/mipnerf_ipe.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='img/mipnerf_ipe.png' width="160">
              </div>
              <script type="text/javascript">
                function mipnerf_start() {
                  document.getElementById('mipnerf_image').style.opacity = "1";
                }

                function mipnerf_stop() {
                  document.getElementById('mipnerf_image').style.opacity = "0";
                }
                mipnerf_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="http://jonbarron.info/mipnerf">
                <papertitle>Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</papertitle>
              </a>
              <br>
              <a href="https://jonbarron.info/">Jonathan T. Barron</a>,
              <strong>Ben Mildenhall</strong>,
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
              <br>
        <em>arXiv</em>, 2021 
              <br>
              <a href="http://jonbarron.info/mipnerf">project page</a>
        /
              <a href="https://arxiv.org/abs/2103.13415">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=EpH175PY1A0">video</a>
              <p></p>
              <p>We prefilter the positional encoding function and train NeRF to generate anti-aliased renderings.</p>
            </td>
          </tr> 


          <tr onmouseout="snerg_stop()" onmouseover="snerg_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='snerg_image'><video  width=100% height=100% muted autoplay loop>
                <source src="img/bakenerf.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='img/bakenerf160.png' width="160">
              </div>
              <script type="text/javascript">
                function snerg_start() {
                  document.getElementById('snerg_image').style.opacity = "1";
                }

                function snerg_stop() {
                  document.getElementById('snerg_image').style.opacity = "0";
                }
                snerg_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="http://nerf.live">
                <papertitle>Baking Neural Radiance Fields for Real-Time View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <strong>Ben Mildenhall</strong>,
              <a href="https://jonbarron.info/">Jonathan T. Barron</a>,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>
              <br>
        <em>arXiv</em>, 2021 
              <br>
              <a href="http://nerf.live">project page</a>
        <!-- / -->
              <!-- <a href="http://arxiv.org/">arXiv</a> -->
        /
              <a href="https://www.youtube.com/watch?v=5jKry8n5YO8">video</a>
        /
              <a href="https://nerf.live/#demos">demo</a>
              <p></p>
              <p>We bake a trained NeRF into a sparse voxel grid of colors and features in order to render it in real-time.</p>
            </td>
          </tr> 


          <tr onmouseout="winr_stop()" onmouseover="winr_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='winr_image'><video  width=100% height=100% muted autoplay loop>
                <source src="img/notre_160.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='img/notre.jpg' width="160">
              </div>
              <script type="text/javascript">
                function winr_start() {
                  document.getElementById('winr_image').style.opacity = "1";
                }

                function winr_stop() {
                  document.getElementById('winr_image').style.opacity = "0";
                }
                winr_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="http://www.matthewtancik.com/learnit">
                <papertitle>Learned Initializations for Optimizing Coordinate-Based Neural Representations</papertitle>
              </a>
              <br>
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Ben Mildenhall*</strong>,
              <a href="https://www.linkedin.com/in/terrance-wang/">Terrance Wang</a>,
              <a href="https://www.linkedin.com/in/divi-schmidt-262044180/">Divi Schmidt</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://jonbarron.info/">Jonathan T. Barron</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2021   <font color="red"><strong>(oral)</strong></font>
              <br>
              <a href="http://www.matthewtancik.com/learnit">project page</a>
        /
              <a href="http://arxiv.org/abs/2012.02189">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=A-r9itCzcyo">video</a>
        /
              <a href="https://github.com/tancik/learnit">code</a>
              <p></p>
              <p>We use meta-learning to find weight initializations for coordinate-based MLPs that allow them to converge faster and generalize better.</p>
            </td>
          </tr> 


          <tr onmouseout="nerv_stop()" onmouseover="nerv_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='nerv_image'><img src='img/hotdog.gif' width="160"></div>
                <img src='img/hotdog.png' width="160">
              </div>
              <script type="text/javascript">
                function nerv_start() {
                  document.getElementById('nerv_image').style.opacity = "1";
                }

                function nerv_stop() {
                  document.getElementById('nerv_image').style.opacity = "0";
                }
                nerv_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://pratulsrinivasan.github.io/nerv/">
                <papertitle>NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://boyangdeng.com/">Boyang Deng</a>,
              <a href="https://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <strong>Ben Mildenhall</strong>,
              <a href="https://jonbarron.info/">Jonathan T. Barron</a>
              <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2021
              <br>
              <a href="https://pratulsrinivasan.github.io/nerv/">project page</a> /
              <a href="https://arxiv.org/abs/2012.03927">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=4XyDdvhhjVo">video</a>
              <p></p>
              <p>We recover relightable NeRF-like models using neural approximations of expensive visibility integrals, so we can simulate complex volumetric light transport during training.</p>
            </td>
          </tr>
    
    
          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='ff_image'><img src='img/lion_ff.png' width="160"></div>
                <img src='img/lion_none.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="fourfeat/index.html">
                <papertitle>Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains
</papertitle>
              </a>
              <br>
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan*</a>,
              <strong>Ben Mildenhall*</strong>,
              <a href="https://people.eecs.berkeley.edu/~sfk/">Sara Fridovich-Keil</a>,
              <a href="https://www.csua.berkeley.edu/~rnithin/">Nithin Raghavan</a>,
              <a href="https://scholar.google.com/citations?user=lvA86MYAAAAJ&hl=en">Utkarsh Singhal</a>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://jonbarron.info/">Jonathan T. Barron</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>NeurIPS</em>, 2020  <font color="red"><strong>(spotlight)</strong></font>
              <br>
              <a href="fourfeat/index.html">project page</a>
        /
              <a href="https://arxiv.org/abs/2006.10739">arXiv</a>
        /
              <a href="https://github.com/tancik/fourier-feature-networks">code</a>
              <p></p>
              <p>We demonstrate that composing fully-connected networks with a simple Fourier feature mapping allows them to learn much high frequency functions.</p>
            </td>
          </tr> 


          <tr onmouseout="nrf_stop()" onmouseover="nrf_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='nrf_image'><video  width="160" muted autoplay loop>
                <source src="img/neural_reflectance.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='img/neural_reflectance.png' width="160">
              </div>
              <script type="text/javascript">
                function nrf_start() {
                  document.getElementById('nrf_image').style.opacity = "1";
                }

                function nrf_stop() {
                  document.getElementById('nrf_image').style.opacity = "0";
                }
                nrf_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2008.03824">
                <papertitle>Neural Reflectance Fields for Appearance Acquisition</papertitle>
              </a>
              <br>
              <a href="http://cseweb.ucsd.edu/~bisai/">Sai Bi*</a>,
              <a href="https://cseweb.ucsd.edu/~zex014/">Zexiang Xu*</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <strong>Ben Mildenhall</strong>,
              <a href="http://www.kalyans.org/">Kalyan Sunkavalli</a>,
              <a href="http://www.miloshasan.net/">Milos Hasan</a>,
              <a href="http://yannickhold.com/">Yannick Hold-Geoffroy</a>,
              <a href="https://cseweb.ucsd.edu/~kriegman/">David Kriegman</a>,
              <a href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
              <br>
        <em>arXiv</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2008.03824">arXiv</a> 
              <p></p>
              <p>We recover relightable NeRF-like models by predicting per-location BRDFs and surface normals, and marching light rays through the NeRV volume to compute visibility.</p>
            </td>
          </tr>
    
    
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='nerf_image'><img src='img/vase_small.gif' width="160"></div>
                <img src='img/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
</papertitle>
              </a>
              <br>
              <strong>Ben Mildenhall*</strong>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <a href="https://jonbarron.info/">Jonathan T. Barron</a>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>European Conference on Computer Vision (ECCV)</em>, 2020   <font color="red"><strong>(Best Paper Honorable Mention)</strong></font>
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">video</a>
        /
              <a href="https://www.youtube.com/watch?v=LRAqeM8EjOo">talk</a>
        /
              <a href="https://github.com/bmild/nerf">code</a>
  /
        <a href="https://www.youtube.com/watch?v=nCpGStnayHk">two minute papers</a>
  /
        <a href="https://paperswithcode.com/method/nerf">papers with code</a>
              <p></p>
              <p>We optimize a simple fully-connected network to represent a single scene as a volume, then use volume rendering to do view synthesis.</p>
            </td>
          </tr> 


          <tr onmouseout="mdp_stop()" onmouseover="mdp_start()">
            <td width="25%">
              <div class="two" id='mdp_image'><video  width="160" muted autoplay loop>
              <source src="img/mdp.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
                <img src='img/mdp.png' width="160">
              </div>
              <script type="text/javascript">
                function mdp_start() {
                  document.getElementById('mdp_image').style.opacity = "1";
                }

                function mdp_stop() {
                  document.getElementById('mdp_image').style.opacity = "0";
                }
                mdp_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2008.01815">
                <papertitle>Deep Multi Depth Panoramas for View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/kaienlin2576/">Kai-En Lin</a>,
              <a href="https://cseweb.ucsd.edu/~zex014/">Zexiang Xu</a>,
              <strong>Ben Mildenhall</strong>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="http://yannickhold.com/">Yannick Hold-Geoffroy</a>,
              <a href="http://www.stephendiverdi.com/">Stephen DiVerdi</a>,
              <a href="https://qisun.me/">Qi Sun</a>,
              <a href="http://www.kalyans.org/">Kalyan Sunkavalli</a>,
              <a href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
              <br>
        <em>European Conference on Computer Vision (ECCV)</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2008.01815">arXiv</a> /
              <a href="https://cseweb.ucsd.edu/~zex014/papers/2020_mdp/2020_mdp.mp4">video</a>
              <p></p>
              <p>We represent scenes as multi-layer panoramas with depth for VR view synthesis.</p>
            </td>
          </tr>

    
          <tr onmouseout="lighthouse_stop()" onmouseover="lighthouse_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='lh_image'><img src='img/rings_crop.gif' width="160"></div>
                <img src='img/rings.png' width="160">
              </div>
              <script type="text/javascript">
                function lighthouse_start() {
                  document.getElementById('lh_image').style.opacity = "1";
                }

                function lighthouse_stop() {
                  document.getElementById('lh_image').style.opacity = "0";
                }
                lighthouse_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://pratulsrinivasan.github.io/lighthouse/">
                <papertitle>Lighthouse: Predicting Lighting Volumes for Spatially-Coherent Illumination</papertitle>
              </a>
              <br>
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan*</a>,
              <strong>Ben Mildenhall*</strong>,
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <a href="https://jonbarron.info/">Jonathan T. Barron</a>,
              <a href="https://research.google/people/RichardTucker/">Richard Tucker</a>,
              <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>
              <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2020  
              <br>
              <a href="https://pratulsrinivasan.github.io/lighthouse/">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08367">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=KsiZpUFPqIU">video</a>
	/
	      <a href="https://github.com/pratulsrinivasan/lighthouse">code</a>
              <p></p>
              <p>We predict a volume from an input stereo pair that can be used to calculate incident lighting at any 3D point within a scene.</p>
            </td>
          </tr>  
    
          <tr onmouseout="stamp_stop()" onmouseover="stamp_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='stamp_image'><img src='img/steg_small.gif' width="160"></div>
                <img src='img/stamp0.png' width="160">
              </div>
              <script type="text/javascript">
                function stamp_start() {
                  document.getElementById('stamp_image').style.opacity = "1";
                }

                function stamp_stop() {
                  document.getElementById('stamp_image').style.opacity = "0";
                }
                stamp_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="http://www.matthewtancik.com/stegastamp">
                <papertitle>StegaStamp: Invisible Hyperlinks in Physical Photographs</papertitle>
              </a>
              <br>
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Ben Mildenhall*</strong>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2020  
              <br>
              <a href="http://www.matthewtancik.com/stegastamp">project page</a>
        /
              <a href="https://arxiv.org/abs/1904.05343">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=E8OqgNDBGO0">video</a>
        /
              <a href="https://github.com/tancik/StegaStamp">code</a>
              <p></p>
              <p>We can hide hyperlinks in natural images to create aesthetically pleasing barcodes.</p>
            </td>
          </tr>  
    
          <tr onmouseout="llff_stop()" onmouseover="llff_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='llff_image'><img src='img/fern160.gif' width="160"></div>
                <img src='img/fern.jpg' width="160">
              </div>
              <script type="text/javascript">
                function llff_start() {
                  document.getElementById('llff_image').style.opacity = "1";
                }

                function llff_stop() {
                  document.getElementById('llff_image').style.opacity = "0";
                }
                llff_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="llff/index.html">
                <papertitle>Local Light Field Fusion: Practical View Synthesis with Prescriptive Sampling Guidelines</papertitle>
              </a>
              <br>
              <strong>Ben Mildenhall*</strong>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan*</a>,
              <a href="https://scholar.google.com/citations?user=yZMAlU4AAAAJ">Rodrigo Ortiz-Cayon</a>,
              <a href="http://faculty.cs.tamu.edu/nimak/">Nima Khademi Kalantari</a>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>,
              <a href="https://abhishekkar.info/">Abhishek Kar</a>
              <br>
        <em>SIGGRAPH</em>, 2019
              <br>
              <a href="llff/index.html">project page</a>
        /
              <a href="https://arxiv.org/abs/1905.00889">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=LY6MgDUzS3M">video</a>
        /
              <a href="https://github.com/Fyusion/LLFF">code</a>
              <p></p>
              <p>We develop and analyze a deep learning method for rendering novel views of complex real world scenes.</p>
            </td>
          </tr>  
    
          <tr onmouseout="unprocessing_stop()" onmouseover="unprocessing_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='unprocessing_image'><img src='img/unprocessing_after.jpg'></div>
                <img src='img/unprocessing_before.jpg'>
              </div>
              <script type="text/javascript">
                function unprocessing_start() {
                  document.getElementById('unprocessing_image').style.opacity = "1";
                }

                function unprocessing_stop() {
                  document.getElementById('unprocessing_image').style.opacity = "0";
                }
                unprocessing_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="http://timothybrooks.com/tech/unprocessing/">
                <papertitle>Unprocessing Images for Learned Raw Denoising</papertitle>
              </a>
              <br>
              <a href="http://timothybrooks.com/">Tim Brooks</a>,
              <strong>Ben Mildenhall</strong>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
              <a href="http://www.dsharlet.com/">Dillon Sharlet</a>,
              <a href="https://jonbarron.info/">Jonathan T. Barron</a>
              <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2019   <font color="red"><strong>(oral)</strong></font>
              <br>
              <a href="http://timothybrooks.com/tech/unprocessing/">project page</a>
	      /
	      <a href="https://arxiv.org/abs/1811.11127">arXiv</a>
              <p></p>
              <p>We can learn a better denoising model by processing and unprocessing images the same way a camera does.</p>
            </td>
          </tr>

    <tr onmouseout="kpn_stop()" onmouseover="kpn_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'kpn_image'><img src='img/kpn1.png' width="160"></div>
        <img src='img/kpn0.png' width="160">
        </div>
        <script type="text/javascript">
        function kpn_start() {
        document.getElementById('kpn_image').style.opacity = "1";
        }
        function kpn_stop() {
        document.getElementById('kpn_image').style.opacity = "0";
        }
        kpn_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="kpn/index.html">
        <papertitle>Burst Denoising with Kernel Prediction Networks</papertitle></a><br>
          <strong>Ben Mildenhall</strong>,
          <a href="http://jonbarron.info">Jonathan T. Barron</a>,
          <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
          Dillon Sharlet,
          <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>,
          Robert Carroll <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018   <font color="red"><strong>(spotlight)</strong></font><br>
        <a href="kpn/index.html">project page</a>
        /
        <a href="https://arxiv.org/abs/1712.02327">arXiv</a>
	/
	<a href="https://github.com/google/burst-denoising">code</a>
        <p></p>
        <p>We train a network to predict linear kernels that denoise bursts of raw linear images.</p>
      </td>
    </tr>

      <tr>
      <tr onmouseout="dcam_stop()" onmouseover="dcam_start()" >
        <td width="25%">
          <div class="one">
          <div class="two" id = 'dcam_image'><img src='img/dcam1.png' width="160"></div>
          <img src='img/dcam0.png' width="160">
          </div>
          <script type="text/javascript">
          function dcam_start() {
          document.getElementById('dcam_image').style.opacity = "1";
          }
          function dcam_stop() {
          document.getElementById('dcam_image').style.opacity = "0";
          }
          dcam_stop()
          </script>
        </td>
        <td width="75%" valign="top">
        <p>
          <a href="https://waller-lab.github.io/DiffuserCam/">
          <papertitle>DiffuserCam: Lensless Single-exposure 3D Imaging</papertitle>
          </a>
          <br>
          <a href="https://people.eecs.berkeley.edu/~nick.antipa/">Nick Antipa</a>, 
          <a href="https://people.eecs.berkeley.edu/~gkuo/">Grace Kuo</a>, 
          <a href="http://www.reinhardheckel.com/">Reinhard Heckel</a>, 
          <strong>Ben Mildenhall</strong>, 
          <a href="https://emrahbostan.com/">Emrah Bostan</a>, 
          <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>, 
            <a href="http://www.laurawaller.com/">Laura Waller</a><br>
          <em>Optica</em>, 2018 <br>
          <a href="https://waller-lab.github.io/DiffuserCam/">project page</a>
          /
          <a href="https://arxiv.org/abs/1710.02134">arXiv</a>
        </p>
        <p>Using a diffuser instead of a lens lets you recover 3D in a single exposure.</p>
        </td>
      </tr>

      <tr>
        <td width="25%"><img src="img/microflakes.png" alt="microflakes" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
          <a href="data/microflake.pdf">
          <papertitle>Approximations for the distribution of microflake normals</papertitle>
          </a>
          <br>
          <a href="https://faculty.engineering.ucdavis.edu/max/">Nelson Max</a>, 
          Tom Duff, 
          <strong>Ben Mildenhall</strong>, 
          <a href="http://students.cec.wustl.edu/~yajieyan/">Yajie Yan</a><br>
          <em>The Visual Computer</em>, 2017
        </p>
        <p>We precompute microflake approximations to make rendering large meshes at a distance more efficient.</p>
        </td>
      </tr>
      <tr>
        <td width="25%"><img src="img/sosmc.png" alt="sosmc" width="160"></td>
        <td width="75%" valign="top">
        <p>
        <p>
          <a href="https://dritchie.github.io/pdf/sosmc.pdf">
          <papertitle>Controlling Procedural Modeling Programs with Stochastically-Ordered Sequential Monte Carlo</papertitle>
          </a>
          <br>
          <a href="https://dritchie.github.io/">Daniel Ritchie</a>, 
          <strong>Ben Mildenhall</strong>, 
          <a href="http://cocolab.stanford.edu/ndg.html">Noah D. Goodman</a>, 
          <a href="https://graphics.stanford.edu/~hanrahan">Pat Hanrahan</a><br>
          <em>SIGGRAPH</em>, 2015
        </p>
        <p>We improve control over the output of highly-variable procedural modeling programs by using SOSMC to provide incremental feedback on partially-generated models.</p>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Course Projects</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><a href="img/objtest20.png"><img src="img/objtest20.png" alt="prl" width="160"></a></td>
        <td width="75%" valign="top">
        <p>
          <a href="data/cs348bproject.pdf">
          <papertitle>Extending the PBRT Renderer to Support Volumetric Light Sources</papertitle>
          </a>
          <br>
          <em>Grand prize in <a href="https://graphics.stanford.edu/courses/cs348b-competition/">CS384B rendering competition</a></em>, Spring 2013
        <p><br>
          Adding support for multicolored, nonhomogeneous, emissive volumes in PBRT 2's path tracing integrator. 
        </p>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="img/cs148_rt.jpg" alt="prl" width="160"></td>
        <td width="75%" valign="top">
        <p>
          <a href="cs148_raytracing">
          <papertitle>Ray Tracer</papertitle>
          </a>
          <br>
          <em>CS148 assignment</em>, Fall 2012
        <p><br>
          Implemented a ray tracer with reflections, refractions, soft shadows, and depth of field.
        </p>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Teaching</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="img/dragon.jpg" alt="dragon" width="160"></td>
        <td width="75%" valign="center">
        <p>
          <a href="https://cs184.eecs.berkeley.edu/su20">
          <papertitle>CS184 - Summer 2020 (Co-instructor)</papertitle>
          </a>
          <br><br>
          <a href="https://cs184.eecs.berkeley.edu/sp17">
          <papertitle>CS184 - Spring 2017 (GSI)</papertitle>
          </a>
          <br><br>
          <a href="https://cs184.eecs.berkeley.edu/sp16">
          <papertitle>CS184 - Spring 2016 (GSI)</papertitle>
          </a>
          <br>
        </p>
        </td>
      </tr>      
      <tr>
        <td>
        <heading>Music</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="img/benpiano.jpeg" alt="piano" width="160"></td>
        <td width="75%" valign="center">
        <p>
          <a href="https://youtu.be/E_DZWgu8Ric">
          <papertitle>Rachmaninoff - Etude-Tableau Op. 39 No. 5</papertitle>
          </a>
          <br>
          Encore after a salon recital, Spring 2019
          <br><br>
          <a href="https://youtu.be/jH2-0KJRH7E">
          <papertitle>Rachmaninoff - Rhapsody on a Theme of Paganini</papertitle> 
          </a><br>
          With Stanford Symphony Orchestra, Spring 2015
          <br><br>
          <a href="https://www.youtube.com/watch?v=0PSZMvJwYEc&list=PLea0bjZsDqxuRL0lCcLZ5oTEu4EVITAmf&index=2">
          <papertitle>Brahms - Piano Quintet</papertitle>
          </a>
          <br>
          Recital at Stanford, Winter 2015
          <br>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          Yep it's another <a href="https://jonbarron.info">Jon Barron</a> website. <br>
          Last updated March 2021.
	    </font>
        </p>
        </td>
      </tr>
      </table>
    </td>
    </tr>
  </table>
  </body>
</html>
