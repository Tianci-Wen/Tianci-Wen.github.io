
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>RawNeRF</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="https://bmild.github.io/rawnerf/img/titlecard-basic.jpg">
    <meta property="og:image:type" content="image/jpeg">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://bmild.github.io/rawnerf"/>
    <meta property="og:title" content="NeRF in the Dark (RawNeRF)" />
    <meta property="og:description" content="NeRF in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images." />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="NeRF in the Dark (RawNeRF)" />
    <meta name="twitter:description" content="NeRF in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images." />
    <meta name="twitter:image" content="https://bmild.github.io/rawnerf/img/titlecard-basic.jpg" />


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
<!--   <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üïØÔ∏è</text></svg>">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110862391-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-110862391-1');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>

<style>
body {
  background-color: black;
  color: white;
}
h2 {
  color: rgb(255,255,255);; 
}
h3 {
  color: white;
}
a {
  color: rgb(50,225,50);
}
</style>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                NeRF in the Dark: </br> High Dynamic Range View Synthesis from Noisy Raw Images</br> 
                <small>
                    CVPR 2022 (Oral Presentation)
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://bmild.github.io/">
                            Ben Mildenhall
                        </a>
                    </li>
                    <li>
                        <a href="https://www.phogzone.com/">
                          Peter Hedman
                        </a>
                    </li>
                    <li>
                        <a href="http://ricardomartinbrualla.com/">
                          Ricardo Martin-Brualla
                        </a>
                    </li>
                    <li>
                        <a href="https://pratulsrinivasan.github.io/">
                          Pratul Srinivasan
                        </a>
                    </li>
                    <li>
                        <a href="https://jonbarron.info/">
                          Jonathan T. Barron
                        </a>
                    </li>
                </ul>

                <ul class="list-inline">
                    <li>
                        Google Research
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2111.13679">
                            <image src="img/rawnerf_paper_thumbnail.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://youtu.be/JtBS4KBcKVc">
                            <image src="img/youtube_icon.png" height="60px"><br>
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="http://storage.googleapis.com/gresearch/refraw360/raw.zip">
                            <image src="img/database_icon.png" height="60px">
                                <h4><strong>Data</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/google-research/multinerf">
                            <image src="img/github_light.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <video id="v0" width="100%" autoplay loop muted controls>
                  <!-- <source src="img/candle_focus_crop.mp4" type="video/mp4" /> -->
                  <source src="img/rawnerf_16x9_showreel_crf23.mp4" type="video/mp4" />
                </video>
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
Neural Radiance Fields (NeRF) is a technique for high quality novel view synthesis from a collection of posed input images. Like most view synthesis methods, NeRF uses tonemapped low dynamic range (LDR) as input; these images have been processed by a lossy camera pipeline that smooths detail, clips highlights, and distorts the simple noise distribution of raw sensor data. We modify NeRF to instead train directly on linear raw images, preserving the scene's full dynamic range. By rendering raw output images from the resulting NeRF, we can perform novel high dynamic range (HDR) view synthesis tasks. In addition to changing the camera viewpoint, we can manipulate focus, exposure, and tonemapping after the fact. Although a single raw image appears significantly more noisy than a postprocessed one, we show that NeRF is highly robust to the zero-mean distribution of raw noise. When optimized over many noisy raw inputs (25-200), NeRF produces a scene representation so accurate that its rendered novel views outperform dedicated single and multi-image deep raw denoisers run on the same wide baseline input images. As a result, our method, which we call <i>RawNeRF</i>, can reconstruct scenes from extremely noisy images captured in near-darkness.
                </p>
                <image src="img/full_pipeline_dark_light.svg" class="img-responsive" alt="overview">
                <!-- <image src="img/full_pipeline_dark.svg" class="img-responsive" alt="overview"  style="max-height: 350px;margin:auto; "> -->
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Overview Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/JtBS4KBcKVc" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    HDR View Synthesis
                </h3>
                <p class="text-justify">
                    RawNeRF output images in linear HDR color space, so its renderings can be retouched like any raw photograph. Here we change the exposure by scaling the linear image values before applying <a href="https://groups.csail.mit.edu/graphics/hdrnet/">HDRNet</a> (Gharbi et al. 2017) to produce a tonemapped low dynamic range output. We can also use the linear colors to render synthetic defocus effects with correctly saturated "bokeh" highlights.
                </p>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/candle_focus_crop.mp4" type="video/mp4" />
                </video>
                <!-- <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/lion_none_gauss_v1.mp4" type="video/mp4" />
                </video> -->
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Denoising
                </h3>
                <p class="text-justify">
                    Training directly on raw data effectively turns RawNeRF into a multi-image denoiser capable of combining information from tens or hundreds of input images. This robustness to noise means that we can use RawNeRF to reconstruct scenes captured in the dark.
                </p>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/grid2x2_crf25.mp4" type="video/mp4" />
                </video>
                <!-- <center>
                <video id="v1" width="50%" autoplay loop muted controls>
                  <source src="img/avenell.mp4" type="video/mp4" /> 
                </video><video id="v2" width="50%" autoplay loop muted controls>
                  <source src="img/notchbush.mp4" type="video/mp4" />
                </video><video id="v3" width="50%" autoplay loop muted controls>
                  <source src="img/bikes.mp4" type="video/mp4" />
                </video><video id="v4" width="50%" autoplay loop muted controls>
                  <source src="img/stove.mp4" type="video/mp4" />
                </video>
            </center> -->
            </div>
        </div>


            


<!--         <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Related links
                </h3>
                <p class="text-justify">
                    Something relevant <a href="google.com">here</a>.
                </p>
            </div>
        </div> -->
        

<!--         <div class="row" id="header_img">
            <figure class="col-md-8 col-md-offset-2">
                <image src="img/llff_teaser.png" class="img-responsive" alt="overview">
                <figcaption>
                </figcaption>
            </figure>
                
        </div> -->
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{mildenhall2022rawnerf,
    title={{NeRF} in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images},
    author={Ben Mildenhall and Peter Hedman and Ricardo Martin-Brualla and Pratul P. Srinivasan and Jonathan T. Barron},
    journal={CVPR},
    year={2022}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    We thank our colleagues on the HDR+ team for answering our questions about how cameras and tonemapping work. <a href="https://bartwronski.com/">Bart Wronski</a> provided helpful feedback on image processing pipeline terminology. 
                    <br>
                The website template was borrowed from <a href="http://mgharbi.com/">Micha√´l Gharbi</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
